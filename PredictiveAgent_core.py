"""
ğŸ¯ PredictiveAgent ä¸»ä½“æ¡†æ¶
Author: DOCTOR + æ­Œè•¾è’‚å¨…

åŸºäº Predictive Coding æ¶æ„é‡æ„çš„æ™ºèƒ½ä½“æ ¸å¿ƒï¼Œæ•´åˆ:
- é¢„æµ‹ç¼–ç å™¨ç”¨äºè¾“å…¥è¯¯å·®ä¼°è®¡ä¸åé¦ˆè°ƒèŠ‚
- å·¥å…·è°ƒç”¨/è®°å¿†æ·»åŠ /é™é»˜å¤„ç†å‡åŸºäºé¢„æµ‹è¯¯å·®é©±åŠ¨
- å¯æ‹“å±•è‡³ QNN åˆ†ç±»å™¨ã€è¯­ä¹‰è®°å¿†åº“ã€CoT æ€ç»´é“¾
"""

import torch
from sentence_transformers import SentenceTransformer
from typing import Tuple,List
from memory_agent import MemoryAgent
from PredictiveCoding import PredictiveCodingAgent
# from tool_agent import call_tool_agent  # å¯é€‰ï¼šå¤–éƒ¨å·¥å…·è°ƒç”¨æ¨¡å—
from CWT_CNN import CWTCNN, generate_cwt_image
from MINLP import AgentOptimizationInterface
import asyncio


class PredictiveAgent:
    def __init__(self):
        self.embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')
        self.dim = self.embedder.get_sentence_embedding_dimension()

        self.memory = MemoryAgent()  # è´Ÿè´£è®°å¿†æ›´æ–°
        self.pc = PredictiveCodingAgent(input_dim=self.dim, hidden_dim=64, memory_threshold=0.07)
        
        self.optimizer = AgentOptimizationInterface()
        self.tool_trigger_threshold = 0.25
        self.memory_trigger_threshold = 0.10
        self.rhythm_model = CWTCNN(input_size=(32, 128), output_dim=3)
        
    async def extract_triplet(self, text: str) -> List[Tuple[str, str, str]]:
        triple = await self.memory.extract_triplet(text)
        return [triple] if triple is not None else []
    
    async def chat(self, prompt: str) -> str:
        # 1. æå–ä¸‰å…ƒç»„
        triples = await self.extract_triplet(prompt) 

        # 2. æ›´æ–°è®°å¿†ï¼ˆåŒ…æ‹¬é€šè¿‡ MPS ç¼–ç å™¨ç”Ÿæˆçš„è®°å¿†å‘é‡ï¼‰
        mps_embedding = self.memory.update_memory_with_mps(triples)
        
        # 3. ç”Ÿæˆå¯¹è¯çš„è¿”å›å†…å®¹
        response = await self.generate_response(prompt, mps_embedding)
        
        return response

    async def generate_response(self, prompt: str, mps_embedding: torch.Tensor) -> str:
        """
        åŸºäºç”¨æˆ·è¾“å…¥å’Œè®°å¿†å‘é‡ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤
        """
        # ä½¿ç”¨è®°å¿†å‘é‡çš„ç»Ÿè®¡ä¿¡æ¯æ¥å½±å“å›å¤ç”Ÿæˆ
        memory_strength = torch.norm(mps_embedding).item()
        memory_summary = f"è®°å¿†å¼ºåº¦: {memory_strength:.3f}"
        
        # è°ƒç”¨LLMç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤
        try:
            from openai import AsyncOpenAI
            client = AsyncOpenAI(
                base_url="https://api.deepseek.com/v1",
                api_key="sk-a8daf58a67d147f2a5cbca304fa01716"
            )
            
            system_prompt = f"""ä½ æ˜¯æ­Œè•¾è’‚å¨…ï¼Œä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚
                            å½“å‰è®°å¿†çŠ¶æ€ï¼š{memory_summary}
                            è¯·åŸºäºç”¨æˆ·çš„è¾“å…¥ç”Ÿæˆè‡ªç„¶ã€æœ‰å¸®åŠ©çš„å›å¤ã€‚"""
            
            response = await client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œè¿”å›åŸºç¡€å›å¤
            return f"æˆ‘ç†è§£äº†æ‚¨çš„é—®é¢˜ï¼š'{prompt}'ã€‚åŸºäºå½“å‰çš„è®°å¿†çŠ¶æ€ï¼ˆ{memory_summary}ï¼‰ï¼Œæˆ‘æ­£åœ¨æ€è€ƒå¦‚ä½•ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚"

    def embed(self, triple: Tuple[str, str, str]) -> torch.Tensor:
        text = f"{triple[0]} â€” {triple[1]} â€” {triple[2]}"
        vec = self.embedder.encode(text, normalize_embeddings=True)
        return torch.tensor(vec).unsqueeze(0)  # shape: (1, dim)

    def check_rhythm_stability(self) -> bool:
        """
        æ£€æŸ¥ç³»ç»ŸèŠ‚å¥ç¨³å®šæ€§
        è¿™é‡Œå¯ä»¥åŸºäºCWT-CNNæ¨¡å‹æˆ–å…¶ä»–æŒ‡æ ‡æ¥åˆ¤æ–­ç³»ç»ŸçŠ¶æ€
        """
        try:
            # ç®€å•çš„ç¨³å®šæ€§æ£€æŸ¥ï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•
            # è¿™é‡Œè¿”å›Trueè¡¨ç¤ºç³»ç»Ÿç¨³å®š
            return True
        except Exception:
            return False

    def process_input(self, triple: Tuple[str, str, str]) -> str:
        vec = self.embed(triple)
        _, _, err = self.pc.forward_predict(vec)
        self.pc.update_memory(vec, err)

        if not self.check_rhythm_stability():
            return "ğŸŒ€ ç³»ç»ŸèŠ‚å¥å¤±ç¨³ï¼Œæš‚åœå†™å…¥"

        if err > self.tool_trigger_threshold:
            return f"ğŸ§° å·¥å…·è°ƒç”¨è§¦å‘ï¼ˆé¢„æµ‹å¤±è´¥ï¼Œè¯¯å·®={err:.4f}ï¼‰"
        elif err > self.memory_trigger_threshold:
            result = self.memory.add(triple)
            return f"ğŸ§  è®°å¿†å·²æ›´æ–°ï¼ˆè¯¯å·®={err:.4f}ï¼‰â†’ {result}"
        else:
            return f"ğŸ”• æ— éœ€å¤„ç†ï¼Œè¯¯å·®ä½äºé˜ˆå€¼ï¼ˆ{err:.4f}ï¼‰"
        
    def update_memory_with_mps(self, triples: List[Tuple[str, str, str]]) -> torch.Tensor:
        """é€šè¿‡ MPS æ›´æ–°è®°å¿†å¹¶è¿”å›å…¨å±€è®°å¿†å‘é‡"""
        mps_embedding = self.memory.update_memory_with_mps(triples)
        return mps_embedding

  
    


if __name__ == '__main__':
    agent = PredictiveAgent()

    samples = [
        ("çŒ«", "æ˜¯", "åŠ¨ç‰©"),
        ("çˆ±å› æ–¯å¦", "æå‡º", "ç›¸å¯¹è®º"),
        ("æˆ‘", "å¾ˆ", "å¼€å¿ƒ"),
        ("åœ°çƒ", "æ˜¯", "æ˜Ÿçƒ"),
    ]

    for t in samples:
        print("\nğŸ“¥ è¾“å…¥ï¼š", t)
        print(agent.process_input(t))
