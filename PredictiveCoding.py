"""
ğŸ§  PredictiveCodingAgent æ¨¡å—
Author: DOCTOR + æ­Œè•¾è’‚å¨… (2025)

æœ¬æ¨¡å—å®ç°ä¸€ä¸ªå…·å¤‡æ„ŸçŸ¥é¢„æµ‹ã€è¯¯å·®åå‘ä¿®æ­£ä¸è®°å¿†æœºåˆ¶çš„åŸºç¡€é¢„æµ‹ç¼–ç  Agentã€‚
è¯¥ç»“æ„å¯ç”¨äºä¸»åŠ¨æ„ŸçŸ¥ã€å¼‚å¸¸æ£€æµ‹ã€æ–°å¥‡æ€§è®°å¿†ã€è‡ªé€‚åº”æ§åˆ¶ç­‰åœºæ™¯ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. encode_input()   - å°†è¾“å…¥ç¼–ç ä¸ºéšçŠ¶æ€å‘é‡
2. decode_prediction() - ä»éšçŠ¶æ€ç”Ÿæˆé¢„æµ‹
3. forward_predict()   - æ‰§è¡Œå¤šè½®é¢„æµ‹-è¯¯å·®-ä¿®æ­£é—­ç¯æ¨ç†
4. update_memory()     - å°†é«˜é¢„æµ‹è¯¯å·®çš„è¾“å…¥è®°å…¥è®°å¿†åº“
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import List, Tuple, Dict, Union
from collections import deque
import math
from MPR import MemoryRetriever
from GMB import GraphMemoryBank
# ======================== TN-MPS è®°å¿†ç¼–ç å™¨ ========================
class TripleCompressor:
    """ğŸ”§ TNå‹ç¼©å™¨ - å°†æ–‡æœ¬ä¸‰å…ƒç»„å‹ç¼©ä¸ºå¼ é‡è¡¨ç¤º"""
    def __init__(self, embed_dim=32):
        self.embed_dim = embed_dim
    
    def text_to_tensor(self, text: str) -> np.ndarray:
        if not isinstance(text, str):
            text = str(text)

        # Step 1: ç¼–ç ä¸ºå­—èŠ‚
        byte_data = text.encode('utf-8', errors='replace')
        safe_length = min(len(byte_data), self.embed_dim)
        truncated = byte_data[:safe_length]
        vec = np.frombuffer(truncated, dtype=np.uint8).astype(np.float32)

        # Step 2: Padding åˆ°æŒ‡å®šé•¿åº¦
        if len(vec) < self.embed_dim:
            vec = np.pad(vec, (0, self.embed_dim - len(vec)), constant_values=0)

        # Step 3: Normalize åˆ° 0~1
        vec /= 255.0

        # Step 4: è‹¥å…¨ä¸º 0ï¼Œåˆ™ fallback ä¸º hash embedding
        if np.allclose(vec, 0.0, atol=1e-6):
            hash_bytes = hashlib.sha256(text.encode()).digest()
            hash_vec = np.frombuffer(hash_bytes[:self.embed_dim], dtype=np.uint8).astype(np.float32) / 255.0
            return hash_vec

        return vec

    
    def compress_triplet(self, triple: Tuple[str, str, str]) -> np.ndarray:
        s_vec = self.text_to_tensor(triple[0])
        p_vec = self.text_to_tensor(triple[1])
        o_vec = self.text_to_tensor(triple[2])
        tensor = np.tensordot(s_vec, p_vec, axes=0)
        tensor = np.tensordot(tensor, o_vec, axes=0)
        return tensor

class MPSMemoryEncoder(nn.Module):
    """ğŸ§  MPSç¼–ç å™¨ - ä½¿ç”¨çŸ©é˜µä¹˜ç§¯çŠ¶æ€ç¼–ç åºåˆ—"""
    def __init__(self, input_dim, feature_dim, bond_dim, output_dim):
        super().__init__()
        self.n_sites = input_dim
        self.feature_dim = feature_dim
        self.bond_dim = bond_dim
        self.mps_cores = nn.ParameterList([
            nn.Parameter(torch.randn(bond_dim, feature_dim, bond_dim)) for _ in range(input_dim)
        ])
        self.start = nn.Parameter(torch.randn(1, bond_dim))
        self.end = nn.Parameter(torch.randn(bond_dim, 1))
        self.fc = nn.Linear(1, output_dim)
        self.norm = nn.LayerNorm(output_dim)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        B = x.shape[0]
        start = self.start.expand(B, -1).unsqueeze(1)
        result = torch.matmul(start, self._contract(x[:, 0, :], self.mps_cores[0]))
        for i in range(1, self.n_sites):
            result = torch.matmul(result, self._contract(x[:, i, :], self.mps_cores[i]))
        end = self.end.unsqueeze(0).expand(B, -1, -1)
        result = torch.matmul(result, end).view(B, 1)
        result = self.fc(result)
        return self.norm(result)
    
    def _contract(self, feature_vec, mps_tensor):
        return torch.einsum('bf,dfr->bdr', feature_vec, mps_tensor)

class IntegratedTN_MPS(nn.Module):
    """ğŸ”§ TN-MPSé›†æˆç³»ç»Ÿ - å°†ä¸‰å…ƒç»„ç¼–ç ä¸ºè®°å¿†å‘é‡"""
    def __init__(self, 
                 tn_embed_dim=32,
                 mps_input_dim=3,
                 mps_bond_dim=16,
                 mps_output_dim=64):
        super().__init__()
        self.tn_compressor = TripleCompressor(embed_dim=tn_embed_dim)
        self.adapter = nn.Sequential(
            nn.Linear(tn_embed_dim**3, 128),
            nn.ReLU(),
            nn.LayerNorm(128),
            nn.Linear(128, tn_embed_dim * 3),
            nn.ReLU()
        )
        self.mps_encoder = MPSMemoryEncoder(
            input_dim=mps_input_dim,
            feature_dim=tn_embed_dim,
            bond_dim=mps_bond_dim,
            output_dim=mps_output_dim
        )
        self.tn_embed_dim = tn_embed_dim
        self.mps_input_dim = mps_input_dim
    
    def forward(self, triples: List[Tuple[str, str, str]]) -> torch.Tensor:
        batch_tensors = []
        for triple in triples:
            tn_tensor = self.tn_compressor.compress_triplet(triple)
            flat_tensor = tn_tensor.flatten()
            adapted = self.adapter(torch.tensor(flat_tensor).float())
            batch_tensors.append(adapted)
        
        batch_size = len(triples)
        seq_input = torch.stack(batch_tensors).view(batch_size, self.mps_input_dim, self.tn_embed_dim)
        return self.mps_encoder(seq_input)

# ======================== ç©ºé—´å¢å¼ºRNNè®°å¿†åº“ ========================
class SpatialMemoryBank(nn.Module):
    """ğŸ§  ç©ºé—´å¢å¼ºè®°å¿†åº“ - æ•´åˆseRNNçš„å…ˆè¿›è®°å¿†ç»“æ„"""
    def __init__(self, input_dim, hidden_dim, capacity=100, 
                 retrieval_k=5, decay_factor=0.95):
        super().__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.capacity = capacity
        self.retrieval_k = retrieval_k
        self.decay_factor = decay_factor
        
        # ç©ºé—´åæ ‡ç³»ç»Ÿ
        self.coords = nn.Parameter(torch.randn(capacity, 2), requires_grad=False)
        
        # è®°å¿†å­˜å‚¨
        self.memory_keys = deque(maxlen=capacity)  # è®°å¿†é”®ï¼ˆä¸‰å…ƒç»„ï¼‰
        self.memory_vectors = deque(maxlen=capacity)  # è®°å¿†å‘é‡
        self.memory_errors = deque(maxlen=capacity)  # é¢„æµ‹è¯¯å·®
        self.memory_activations = deque(maxlen=capacity)  # ç©ºé—´æ¿€æ´»å€¼
        
        # seRNNç»„ä»¶
        self.input2hidden = nn.Linear(input_dim, hidden_dim)
        self.hidden2hidden = nn.Linear(hidden_dim, hidden_dim)
        self.spatial_weights = nn.Parameter(torch.randn(hidden_dim, 2))
        
        # è‡ªé€‚åº”æ£€ç´¢é—¨
        self.retrieval_gate = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.Sigmoid()
        )
    
    def spatial_activation(self):
        """è®¡ç®—æ‰€æœ‰è®°å¿†çš„ç©ºé—´æ¿€æ´»å€¼ - åŸºäºå‡ ä½•è·ç¦»"""
        if len(self.memory_vectors) == 0:
            return torch.tensor([])
        
        # è®¡ç®—å…¨å±€ä¸­å¿ƒç‚¹
        center = self.spatial_weights.mean(dim=0)
        
        # è®¡ç®—æ‰€æœ‰åæ ‡åˆ°ä¸­å¿ƒçš„è·ç¦»
        dists = torch.norm(self.coords[:len(self.memory_vectors)] - center, dim=1)
        activations = 1.0 / (1.0 + dists)
        return activations
    
    def add_memory(self, key, vector, error):
        """æ·»åŠ æ–°è®°å¿†åˆ°è®°å¿†åº“"""
        # å¦‚æœè®°å¿†åº“æ»¡äº†ï¼Œæ‰¾åˆ°æ¿€æ´»å€¼æœ€ä½çš„è®°å¿†æ›¿æ¢
        if len(self.memory_vectors) >= self.capacity:
            min_act_idx = torch.argmin(torch.tensor(self.memory_activations)).item()
            # æ›¿æ¢æ¿€æ´»å€¼æœ€ä½çš„è®°å¿†
            self.memory_keys[min_act_idx] = key
            self.memory_vectors[min_act_idx] = vector
            self.memory_errors[min_act_idx] = error
        else:
            # æ·»åŠ æ–°è®°å¿†
            self.memory_keys.append(key)
            self.memory_vectors.append(vector)
            self.memory_errors.append(error)
        
        # æ›´æ–°ç©ºé—´æ¿€æ´»å€¼
        self._update_activations()
    
    def _update_activations(self):
        """æ›´æ–°æ‰€æœ‰è®°å¿†çš„ç©ºé—´æ¿€æ´»å€¼"""
        activations = self.spatial_activation()
        if len(activations) == 0:
            self.memory_activations = deque(maxlen=self.capacity)
            return
        
        # æ›´æ–°æ¿€æ´»å€¼é˜Ÿåˆ—
        self.memory_activations = deque(activations.tolist(), maxlen=self.capacity)
    
    # åœ¨ SpatialMemoryBank ç±»ä¸­ä¿®æ”¹ retrieve_memories æ–¹æ³•
    def retrieve_memories(self, query_vector: torch.Tensor) -> Tuple[List, List[torch.Tensor]]:
        """å¥å£®çš„å†…å­˜æ£€ç´¢å®ç° - åŒæ—¶è§£å†³ç»´åº¦ä¸åŒ¹é…å’Œåˆ—è¡¨ç´¢å¼•é—®é¢˜"""
        if len(self.memory_vectors) == 0:
            return [], []
        
        # æ­¥éª¤1: ç¡®ä¿æŸ¥è¯¢å‘é‡ç»´åº¦æ­£ç¡® (1, D)
        query_vector = self._ensure_2d(query_vector)
        
        # æ­¥éª¤2: å‡†å¤‡å†…å­˜å‘é‡å¼ é‡ (M, D)
        mem_vectors = self._prepare_memory_tensor()
        
        # æ­¥éª¤3: è®¡ç®—ç›¸ä¼¼åº¦ (M,)
        sim = F.cosine_similarity(query_vector.expand_as(mem_vectors), mem_vectors, dim=1)
        
        # æ­¥éª¤4: æ·»åŠ ç©ºé—´æ¿€æ´»å€¼
        if len(self.memory_activations) == len(sim):
            total_sim = sim + torch.tensor(self.memory_activations, device=query_vector.device)
        else:
            total_sim = sim
        
        # æ­¥éª¤5: è·å–Top-Kç´¢å¼• (å¥å£®å¤„ç†)
        k = min(self.retrieval_k, len(total_sim))
        topk_idxs = self._get_topk_indices(total_sim, k)
        
        # æ­¥éª¤6: æ£€ç´¢ç»“æœ (ç»Ÿä¸€ç»´åº¦)
        retrieved_keys = [self.memory_keys[i] for i in topk_idxs]
        retrieved_vectors = [self._ensure_2d(self.memory_vectors[i]) for i in topk_idxs]
        
        return retrieved_keys, retrieved_vectors
    
    def contextualize(self, query_vector: torch.Tensor, retrieved_vectors: List[torch.Tensor]) -> torch.Tensor:
        """ä¸Šä¸‹æ–‡èåˆæ–¹æ³• - å¤„ç†å„ç§å‘é‡ç»´åº¦"""
        if not retrieved_vectors:
            return self._ensure_2d(query_vector)
        
        # å‡†å¤‡è¾“å…¥åºåˆ—ï¼šå½“å‰æŸ¥è¯¢ + æ£€ç´¢çš„è®°å¿†
        vectors = [self._ensure_2d(vec) for vec in [query_vector] + retrieved_vectors]
        inputs = torch.cat(vectors, dim=0)  # (1+k, D)
        
        # seRNNå¤„ç†
        h = torch.zeros(1, self.hidden_dim, device=query_vector.device)
        for t in range(inputs.size(0)):
            x_t = inputs[t].unsqueeze(0)  # (1, D)
            h = torch.tanh(self.input2hidden(x_t) + self.hidden2hidden(h))
        
        # è‡ªé€‚åº”é—¨æ§èåˆ
        gate = self.retrieval_gate(query_vector)
        contextualized = gate * h + (1 - gate) * self.input2hidden(self._ensure_2d(query_vector))
        
        return contextualized
    
    # ======== è¾…åŠ©æ–¹æ³• ========
    
    def _ensure_2d(self, tensor: torch.Tensor) -> torch.Tensor:
        """ç¡®ä¿å¼ é‡æ˜¯äºŒç»´çš„: (1, D)"""
        if tensor.dim() == 1:
            return tensor.unsqueeze(0)
        if tensor.dim() == 3:
            return tensor.squeeze(0)
        return tensor
    
    def _prepare_memory_tensor(self) -> torch.Tensor:
        """å‡†å¤‡å†…å­˜å¼ é‡ (M, D)"""
        mem_tensors = []
        for vec in self.memory_vectors:
            # ç»Ÿä¸€ä¸º2Då¼ é‡å¹¶å‹ç¼©æ‰¹æ¬¡ç»´åº¦
            vec_2d = self._ensure_2d(vec)
            mem_tensors.append(vec_2d.squeeze(0))  # ä»(1,D)å˜ä¸º(D)
        
        return torch.stack(mem_tensors)  # (M, D)
    
    def _get_topk_indices(self, similarities: torch.Tensor, k: int) -> List[int]:
        """å¥å£®è·å–Top-Kç´¢å¼•ï¼Œè¿”å›æ•´æ•°åˆ—è¡¨"""
        topk_values, topk_indices = torch.topk(similarities, k)
        
        if k == 1:
            # å•å…ƒç´ æƒ…å†µ
            return [topk_indices.item()]
        
        # å¤šå…ƒç´ æƒ…å†µ
        return topk_indices.tolist()
    
    def add_memory(self, key, vector: torch.Tensor, error):
            target_dim = 384  # æ ¹æ®æ¨¡å‹é…ç½®è®¾å®š
            vector = self._ensure_2d(vector)
            if vector.size(1) != target_dim:
                if vector.size(1) < target_dim:
                   # å¡«å……é›¶å€¼è‡³ç›®æ ‡ç»´åº¦
                   pad_size = target_dim - vector.size(1)
                   vector = torch.cat([vector, torch.zeros(1, pad_size)], dim=1)
                else:
                    # è£å‰ªè‡³ç›®æ ‡ç»´åº¦
                    vector = vector[:, :target_dim]
    
             # 2. æ ¡éªŒç»´åº¦ä¸€è‡´æ€§ï¼ˆé˜²å¾¡æ€§ç¼–ç¨‹ï¼‰
            assert vector.size(1) == target_dim, \
                f"å‘é‡ç»´åº¦å¿…é¡»ä¸º{target_dim}ï¼Œå½“å‰ä¸º{vector.size(1)}"
    
            # 3. æ”¹è¿›è®°å¿†æ›¿æ¢é€»è¾‘
            if len(self.memory_vectors) >= self.capacity:
                min_act_idx = torch.argmin(torch.tensor(self.memory_activations)).item()
                # ä»…å½“æ–°å‘é‡ç»´åº¦ä¸æ—§å‘é‡ä¸€è‡´æ—¶æ‰æ›¿æ¢
                if self.memory_vectors[min_act_idx].size(1) == target_dim:
                    self.memory_keys[min_act_idx] = key
                    self.memory_vectors[min_act_idx] = vector
                    self.memory_errors[min_act_idx] = error
                else:
                    # ç»´åº¦ä¸åŒ¹é…æ—¶è·³è¿‡æ›¿æ¢æˆ–æ‰©å®¹
                    self.memory_keys.append(key)
                    self.memory_vectors.append(vector)
                    self.memory_errors.append(error)
            else:
                    self.memory_keys.append(key)
                    self.memory_vectors.append(vector)
                    self.memory_errors.append(error)
    
            # 4. æ›´æ–°æ¿€æ´»çŠ¶æ€
            self._update_activations()

    
    def contextualize(self, query_vector, retrieved_vectors):
        if not retrieved_vectors:
            return self._ensure_2d(query_vector)
        inputs = [self._ensure_2d(query_vector)] + [self._ensure_2d(vec) for vec in retrieved_vectors]
        inputs = torch.cat(inputs, dim=0)
        h = torch.zeros(1, self.hidden_dim, device=query_vector.device)
        for t in range(inputs.size(0)):
            x_t = inputs[t].unsqueeze(0)
            h = torch.tanh(self.input2hidden(x_t) + self.hidden2hidden(h))
        gate = self.retrieval_gate(query_vector)
        projected_query = self.input2hidden(self._ensure_2d(query_vector))
        contextualized = gate * h + (1 - gate) * projected_query
        return contextualized

    
    def decay_activations(self):
        """è¡°å‡è®°å¿†æ¿€æ´»å€¼ - æ¨¡æ‹Ÿè®°å¿†è¡°å‡"""
        if len(self.memory_activations) == 0:
            return
        
        # è¡°å‡æ¿€æ´»å€¼
        new_activations = [act * self.decay_factor for act in self.memory_activations]
        self.memory_activations = deque(new_activations, maxlen=self.capacity)

    def get_all_memories(self):
        """è·å–å½“å‰æ‰€æœ‰è®°å¿†é”®å’Œå‘é‡"""
        if not self.memory_keys or not self.memory_vectors:
            return [], []
        
        # ç¡®ä¿å‘é‡ç»´åº¦ä¸€è‡´ (1, D)
        vectors = [self._ensure_2d(vec) for vec in self.memory_vectors]
        return list(self.memory_keys), vectors
# ======================== é¢„æµ‹ç¼–ç æ™ºèƒ½ä½“ ========================
class PredictiveCodingAgent(nn.Module):
    """ğŸ§  é¢„æµ‹ç¼–ç æ™ºèƒ½ä½“ - æ•´åˆTN-MPSç¼–ç å™¨å’Œç©ºé—´è®°å¿†åº“"""
    def __init__(self, tn_embed_dim=32,mps_bond_dim=16,mps_output_dim=384,hidden_dim=384,memory_capacity=200,memory_threshold=0.1,graph_memory_bank=None):
        super().__init__()
        

        # è®°å¿†ç¼–ç ç³»ç»Ÿ
        self.memory_encoder = IntegratedTN_MPS(
            tn_embed_dim=tn_embed_dim,
            mps_bond_dim=mps_bond_dim,
            mps_output_dim=mps_output_dim
        )
        
        # ç©ºé—´å¢å¼ºè®°å¿†åº“
        self.memory_bank = SpatialMemoryBank(
            input_dim=mps_output_dim,
            hidden_dim=hidden_dim,
            capacity=memory_capacity
        )
        
        # é¢„æµ‹ç¼–ç ç»„ä»¶
        self.input_dim = mps_output_dim
        self.hidden_dim = hidden_dim
        self.encoder = nn.Sequential(
            nn.Linear(self.input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.Linear(hidden_dim, self.input_dim),
            nn.LayerNorm(self.input_dim)
        )
        
        # ä¸Šä¸‹æ–‡åˆ°è®°å¿†ç»´åº¦çš„æŠ•å½±å±‚
        self.context_to_memory_dim = nn.Linear(hidden_dim, mps_output_dim)
        
        # è®°å¿†å‚æ•°
        self.memory_threshold = memory_threshold
        self.memory_update_freq = 5
        self.step_count = 0

        self.MPR = MemoryRetriever(memory_embeddings=[],memory_triples=[],similarity_threshold=0.7)

        # æ–°å¢å›¾è®°å¿†åº“
        self.graph_memory = graph_memory_bank or GraphMemoryBank()
    def encode_input(self, triples: List[Tuple[str, str, str]]) -> torch.Tensor:
        """ç¼–ç ä¸‰å…ƒç»„ä¸ºè®°å¿†å‘é‡ï¼ˆå¸¦æ¢¯åº¦ä¿æŠ¤ï¼‰"""
        with torch.no_grad():
            return self.memory_encoder(triples)
    
    def predict_with_memory(self, query_vector: torch.Tensor) -> torch.Tensor:
        """ä½¿ç”¨MPRæ£€ç´¢å™¨çš„è®°å¿†å¢å¼ºé¢„æµ‹"""
        # ç¡®ä¿æŸ¥è¯¢å‘é‡æ˜¯äºŒç»´çš„ (1, D)
        query_vector = self.memory_bank._ensure_2d(query_vector)
    
        retrieved_vectors = []
    
        if len(self.memory_bank.memory_keys) > 0:
            # 1. è·å–å½“å‰æ‰€æœ‰è®°å¿†
            keys, vectors = self.memory_bank.get_all_memories()
        
            # 2. å‡†å¤‡numpyæ ¼å¼çš„è®°å¿†å‘é‡
            vectors_np = [vec.detach().cpu().numpy().flatten() for vec in vectors]
        
            # 3. æ›´æ–°MPRè®°å¿†åº“ï¼ˆå‡è®¾æœ‰å¯¹åº”æ–¹æ³•ï¼‰
            # è¿™é‡Œä¸è¦è°ƒç”¨ retrieveï¼Œè€Œæ˜¯è°ƒç”¨æ›´æ–°è®°å¿†åº“çš„æ–¹æ³•ï¼Œæ¯”å¦‚ï¼š
            self.MPR.set_memory(vectors_np, keys)  # ä½ éœ€è¦è‡ªå·±å®ç°è¿™ä¸ªæ–¹æ³•
        
           # 4. å‡†å¤‡æŸ¥è¯¢å‘é‡ï¼ˆnumpyæ ¼å¼ï¼‰
            query_np = query_vector.detach().cpu().numpy().flatten()
        
            # 5. æ‰§è¡ŒMPRæ£€ç´¢ï¼Œä½¿ç”¨å…³é”®å­—å‚æ•°
            indices = self.MPR.retrieve(vectors=[query_np], top_k=5)  # è¿™é‡Œä¼ å…¥åˆ—è¡¨åŒ…è£¹query_np
        
            # 6. æ ¹æ®indiceså–å¯¹åº”å‘é‡ï¼ˆä½ å¯èƒ½éœ€è¦å®ç°retrieveè¿”å›çš„å…·ä½“å†…å®¹ï¼‰
            for idx in indices[0]:  # indices[0]æ˜¯ç¬¬ä¸€ä¸ªæŸ¥è¯¢çš„top_kç»“æœ
                vec_np = vectors_np[idx]
                vec_tensor = torch.tensor(vec_np, device=query_vector.device, dtype=torch.float32).view(1, -1)
                retrieved_vectors.append(vec_tensor)
    
        # 7. ä½¿ç”¨æ£€ç´¢åˆ°çš„è®°å¿†è¿›è¡Œä¸Šä¸‹æ–‡èåˆ
        if retrieved_vectors:
            contextualized = self.memory_bank.contextualize(query_vector, retrieved_vectors)
        else:
            contextualized = query_vector
    
         # 8. æŠ•å½±åˆ°ç›®æ ‡ç»´åº¦
        if contextualized.size(-1) == self.hidden_dim:
            contextualized = self.context_to_memory_dim(contextualized)
    
        # 9. é¢„æµ‹
        h = self.encoder(contextualized)
        return self.decoder(h)



    def forward(self, triples: List[Tuple[str, str, str]]) -> Tuple[torch.Tensor, float]:
        # 1. ç¼–ç è¾“å…¥ä¸ºè®°å¿†å‘é‡
        memory_vector = self.encode_input(triples)
        
        # 2. å¾ªç¯å¤„ç†æ¯ä¸ªä¸‰å…ƒç»„
        predictions = []
        errors = []
        for i in range(len(triples)):
            # å¤„ç†å•ä¸ªä¸‰å…ƒç»„
            single_vector = memory_vector[i].unsqueeze(0)
            triple = triples[i]
            
            # 3. è®°å¿†å¢å¼ºé¢„æµ‹
            prediction = self.predict_with_memory(single_vector)
            predictions.append(prediction)
            
            # 4. è®¡ç®—é¢„æµ‹è¯¯å·®
            with torch.no_grad():
                error = F.mse_loss(prediction, single_vector).item()
                errors.append(error)
            
            # 5. æ›´æ–°è®°å¿†åº“ï¼ˆå¦‚æœè¯¯å·®é«˜ï¼‰
            if error > self.memory_threshold:
                self.memory_bank.add_memory(
                    key=triple,
                    vector=single_vector.detach().clone(),
                    error=error
                )
                
                # æ–°å¢ï¼šæ·»åŠ åˆ°å›¾è®°å¿†åº“
                self.graph_memory.add_triplet(
                    triple=triple,
                    vector=single_vector.detach().clone(),
                    error=error
                )
        
        # 6. å®šæœŸç»´æŠ¤è®°å¿†åº“
        self.step_count += 1
        if self.step_count % self.memory_update_freq == 0:
            self.memory_bank.decay_activations()
        
        predictions_tensor = torch.cat(predictions, dim=0)
        avg_error = sum(errors) / len(errors) if errors else 0.0
        return predictions_tensor, avg_error
    
    def recall_memory(self, query_triple: Tuple[str, str, str]) -> List[Tuple[str, str, str]]:
        # 1. ä»å›¾è®°å¿†åº“ä¸­æ£€ç´¢
        graph_results = []
        for ent in [query_triple[0], query_triple[2]]:
            graph_results.extend(self.graph_memory.get_neighbors(ent))
    
        """ä½¿ç”¨MPRæ£€ç´¢å™¨å›å¿†ä¸æŸ¥è¯¢ç›¸å…³çš„è®°å¿†"""
        # 1. ç¼–ç æŸ¥è¯¢ä¸‰å…ƒç»„
        query_vector = self.encode_input([query_triple])
        query_vector = self.memory_bank._ensure_2d(query_vector[0])

        # 2. å‡†å¤‡æŸ¥è¯¢å‘é‡ï¼ˆnumpyæ ¼å¼ï¼‰
        query_np = query_vector.detach().cpu().numpy().flatten()

        # 3. æ‰§è¡Œæ£€ç´¢ï¼šMPR å†…éƒ¨è´Ÿè´£å‘é‡æ¯”å¯¹ + è¿”å›ä¸‰å…ƒç»„
        # è¿™é‡Œæ”¹ä¸ºç”¨å…³é”®å­—å‚æ•° vectorsï¼Œä¸”ä¼ å…¥åˆ—è¡¨å½¢å¼
        retrieved_triples = self.MPR.retrieve(vectors=[query_np.tolist()], top_k=5)

        # 4. ç»“æ„è¿‡æ»¤ï¼šé¿å… downstream è§£åŒ…å¤±è´¥
        valid_triples = [t for t in retrieved_triples if isinstance(t, (tuple, list)) and len(t) == 3]

        return valid_triples


    
    def memory_stats(self) -> Dict[str, float]:
        """è·å–è®°å¿†åº“ç»Ÿè®¡ä¿¡æ¯"""
        if not self.memory_bank.memory_errors:
            return {
                'size': 0,
                'avg_error': 0,
                'min_error': 0,
                'max_error': 0,
            }
        
        return {
            'size': len(self.memory_bank.memory_vectors),
            'avg_error': sum(self.memory_bank.memory_errors) / len(self.memory_bank.memory_errors),
            'min_error': min(self.memory_bank.memory_errors),
            'max_error': max(self.memory_bank.memory_errors),
        }
    def load_memory(self, path_prefix="graph_memory"):
        """ä» GMB åŠ è½½ï¼Œå¹¶è¿˜åŸè‡³è¿è¡Œæ—¶è®°å¿†åº“"""
        self.graph_memory.load_all(path_prefix)

        for edge in self.graph_memory.graph_edges:
            triple = (edge["from"], edge["label"], edge["to"])
            s_id = edge["from"]
            o_id = edge["to"]

            s_vec = self.graph_memory.graph_nodes.get(s_id, {}).get("vector", None)
            o_vec = self.graph_memory.graph_nodes.get(o_id, {}).get("vector", None)



            if s_vec and o_vec:
                s_tensor = torch.tensor(s_vec)
                o_tensor = torch.tensor(o_vec)
            if s_vec and o_vec:
                s_tensor = torch.tensor(s_vec)
                o_tensor = torch.tensor(o_vec)
    
            # åŠ¨æ€å¯¹é½ç»´åº¦ï¼šå–æœ€å°å…¬å…±é•¿åº¦ï¼ˆä¼˜å…ˆæ–¹æ¡ˆï¼‰
                min_dim = min(len(s_tensor), len(o_tensor))
                s_aligned = s_tensor[:min_dim]
                o_aligned = o_tensor[:min_dim]
                vector = (s_aligned + o_aligned) / 2
    
               # æŠ•å½±å˜æ¢æ›¿ä»£è£å‰ª/å¡«å……ï¼ˆå½“è¯­ä¹‰ç©ºé—´ä¸ä¸€è‡´æ—¶ï¼‰
               # projection = nn.Linear(64, 384)  # éœ€é¢„è®­ç»ƒæƒé‡
               # o_projected = projection(o_tensor.float())
               # vector = (s_tensor + o_projected) / 2
    
                # æ·»åŠ è®°å¿†ï¼ˆç»Ÿä¸€ç§»è‡³åˆ†æ”¯å¤–ï¼‰
                self.memory_bank.add_memory(
                    key=triple,
                    vector=vector.unsqueeze(0),
                    error=edge["error"]
                )
            
                


# ======================== æµ‹è¯•å‡½æ•° ========================
def test_memory_agent():
    print("\n=== ğŸ§ª ç©ºé—´å¢å¼ºè®°å¿†æ™ºèƒ½ä½“æµ‹è¯• ===")
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = PredictiveCodingAgent(
        tn_embed_dim=32,
        mps_bond_dim=16,
        mps_output_dim=64,
        hidden_dim=128,
        memory_capacity=50,
        memory_threshold=0.05
    )
    
    # æµ‹è¯•æ•°æ®
    test_triples = [
        ("çˆ±å› æ–¯å¦", "æå‡º", "ç›¸å¯¹è®º"),
        ("ç‰›é¡¿", "å‘ç°", "ä¸‡æœ‰å¼•åŠ›"),
        ("å›¾çµ", "å‘æ˜", "å›¾çµæœº")
    ]
    
    # åˆå§‹é¢„æµ‹
    prediction, err = agent.forward(test_triples)
    print(f"âœ… åˆå§‹é¢„æµ‹è¯¯å·®: {err:.4f}")
    
    # æ·»åŠ æ›´å¤šè®°å¿†
    for i in range(5):
        new_triple = (f"ç§‘å­¦å®¶{i}", f"å‘ç°{i}", f"ç†è®º{i}")
        agent.forward([new_triple])
        print(f"å·²æ·»åŠ è®°å¿† {i+1}/5")
    
    # æµ‹è¯•è®°å¿†å›å¿†
    query = ("çˆ±å› æ–¯å¦", "æå‡º", "ç›¸å¯¹è®º")
    recalled = agent.recall_memory(query)
    print(f"\nğŸ” å›å¿†ä¸æŸ¥è¯¢ç›¸å…³çš„è®°å¿†:")
    for i, mem in enumerate(recalled[:3]):
        print(f"  è®°å¿†{i+1}: {mem}")
    
    # è·å–è®°å¿†ç»Ÿè®¡
    stats = agent.memory_stats()
    print(f"\nğŸ“Š è®°å¿†åº“ç»Ÿè®¡:")
    print(f"  å¤§å°: {stats['size']}")
    print(f"  å¹³å‡è¯¯å·®: {stats['avg_error']:.4f}")
    print(f"  æœ€å°è¯¯å·®: {stats['min_error']:.4f}")
    print(f"  æœ€å¤§è¯¯å·®: {stats['max_error']:.4f}")
    
    # æ¢¯åº¦æµ‹è¯•
    target = torch.randn_like(prediction)
    loss = F.mse_loss(prediction, target)
    loss.backward()
    print("\nâœ… æ¢¯åº¦åå‘ä¼ æ’­æˆåŠŸ")
    
    print("\nğŸ§ª æµ‹è¯•é€šè¿‡ï¼")

if __name__ == "__main__":
    test_memory_agent()