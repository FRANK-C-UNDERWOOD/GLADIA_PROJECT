"""
ğŸ§  seRNN æ¨¡å—ï¼šSpatially-Embedded Recurrent Neural Network
Author: DOCTOR + æ­Œè•¾è’‚å¨… (2025)

æ¨¡å—ç”¨é€”ï¼š
- åœ¨ RNN ä¸­åŠ å…¥â€œç¥ç»å…ƒç©ºé—´ä½ç½®â€ä½œä¸ºè¿æ¥ç»“æ„é™åˆ¶
- å®ç°ç©ºé—´ç¨€ç–æ€§çº¦æŸï¼Œæ›´ç¬¦åˆç”Ÿç‰©ç¥ç»ç½‘ç»œçš„è¿æ¥æ¨¡å¼
- å¯ç”¨äº Agent ç©ºé—´å¯¼èˆªè®°å¿†ã€è„‘è¿æ¥æ¨¡æ‹Ÿã€å›¾å¼è®°å¿†å»ºæ„

ä¸»è¦ç»„ä»¶ï¼š
1. seRNNCell       - å•ä¸ªæ—¶é—´æ­¥çš„å¸¦ç©ºé—´æƒ©ç½šçš„ RNN å•å…ƒ
2. seRNN           - å¤šæ­¥åºåˆ—å»ºæ¨¡çš„å¾ªç¯ç½‘ç»œç»“æ„
3. spatial_regularizer - è¿æ¥è·ç¦»æ­£åˆ™é¡¹ï¼ˆç”¨äºåŠ æƒ lossï¼‰
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class seRNNCell(nn.Module):
    def __init__(self, input_size, hidden_size, neuron_coords: torch.Tensor):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.coords = neuron_coords  # shape: (hidden_size, 2)
        
        # ä¿®å¤æƒé‡ç»´åº¦
        self.W_in = nn.Linear(input_size, hidden_size)
        self.W_hh = nn.Linear(hidden_size, hidden_size, bias=False)  # æ”¹ä¸ºLinearå±‚
        self.bias = nn.Parameter(torch.zeros(hidden_size))
        
        # ä¿å­˜åŸå§‹æƒé‡ç”¨äºæ­£åˆ™è®¡ç®—
        self.raw_W_hh = self.W_hh.weight  # (hidden_size, hidden_size)

    def forward(self, x, h_prev):
        # ä¿®å¤ç»´åº¦åŒ¹é…é—®é¢˜
        h_linear = self.W_in(x) + self.W_hh(h_prev) + self.bias
        h_new = torch.tanh(h_linear)
        return h_new

    def spatial_regularizer(self):
        """ä¿®æ­£æ­£åˆ™é¡¹è®¡ç®—é€»è¾‘"""
        dist = torch.cdist(self.coords, self.coords, p=2)  # (N, N)
        # ç‚¹ç§¯è®¡ç®—ï¼šâˆ‘|W| * dist
        cost = torch.sum(torch.abs(self.raw_W_hh) * dist)
        return cost


class seRNN(nn.Module):
    def __init__(self, input_size, hidden_size, neuron_coords: torch.Tensor):
        super().__init__()
        self.hidden_size = hidden_size
        self.cell = seRNNCell(input_size, hidden_size, neuron_coords)

    def forward(self, x):
        B, T, D = x.shape
        # æ·»åŠ è®¾å¤‡ä¿¡æ¯
        device = x.device
        h = torch.zeros(B, self.hidden_size, device=device)
        h_seq = []
        
        for t in range(T):
            h = self.cell(x[:, t, :], h)
            h_seq.append(h.unsqueeze(1))
            
        return torch.cat(h_seq, dim=1)

    def get_spatial_cost(self):
        return self.cell.spatial_regularizer()


if __name__ == "__main__":
    # ğŸ‘¾ ç¤ºä¾‹ï¼š10ç»´è¾“å…¥ â†’ 16ç»´ç©ºé—´ç¥ç»å…ƒ â†’ åºåˆ—é•¿åº¦ 5
    coords = torch.rand(16, 2)  # éšæœºåˆ†å¸ƒçš„ç¥ç»å…ƒåæ ‡
    model = seRNN(input_size=10, hidden_size=16, neuron_coords=coords)

    seq_input = torch.randn(4, 5, 10)  # (batch, time, input_dim)
    out = model(seq_input)
    print("ğŸ”® è¾“å‡º shape:", out.shape)
    print("ğŸ“ ç©ºé—´è¿æ¥æˆæœ¬:", model.get_spatial_cost().item())
