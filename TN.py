"""
ğŸ§ ğŸ§  Tensor Network Compression Module for Triple Embeddings
Inspired by the paper: "Compressing Neural Networks Using Tensor Networks with Exponentially Fewer Variational Parameters"
Author: DOCTOR + æ­Œè•¾è’‚å¨… (2025)
"""

import numpy as np
from typing import Tuple, List

class TripleCompressor:
    """ğŸ”§ğŸ”§ ä¸‰å…ƒç»„å¼ é‡å‹ç¼©å™¨ï¼šä½¿ç”¨å¼ é‡ç½‘ç»œæŠ€æœ¯å°†æ–‡æœ¬ä¸‰å…ƒç»„å‹ç¼©ä¸ºç´§å‡‘å¼ é‡è¡¨ç¤º\n
    å·¥ä½œåŸç†ï¼šå°†æ–‡æœ¬ç¼–ç ä¸ºå‘é‡ â†’ æ„å»ºé«˜é˜¶å¼ é‡ â†’ æ‰§è¡Œå¼ é‡ç½‘ç»œå‹ç¼© â†’ è¾“å‡ºç´§å‡‘è¡¨ç¤º\n
    ç‰¹ç‚¹ï¼šå›ºå®šç»´åº¦è¾“å‡ºã€æ”¯æŒæ‰¹é‡å¤„ç†ã€å¯è§†åŒ–è°ƒè¯•åŠŸèƒ½"""
    
    def __init__(self, embed_dim=32, mode=None):
        """
        ğŸ”§ğŸ”§ åˆå§‹åŒ–å‹ç¼©å™¨é…ç½®\n
        å‚æ•°ï¼š
        embed_dim -- æ–‡æœ¬ç¼–ç çš„å›ºå®šç»´åº¦ï¼ˆé»˜è®¤32ï¼‰
        """
        self.embed_dim = embed_dim
        self.mode = mode if mode else "default"
    
    def text_to_tensor(self, text: str) -> np.ndarray:
        """
        ğŸ“ğŸ“ å¢å¼ºç‰ˆæ–‡æœ¬ç¼–ç å™¨ï¼šå®‰å…¨å¤„ç†å¤šå­—èŠ‚å­—ç¬¦
        æ”¹è¿›ç‚¹ï¼š
        1. ä½¿ç”¨ç¼–ç é”™è¯¯å¤„ç†ç­–ç•¥
        2. é¿å…æˆªæ–­å¤šå­—èŠ‚å­—ç¬¦
        3. æ·»åŠ é•¿åº¦æ ¡éªŒæœºåˆ¶
        """
        # å®‰å…¨ç¼–ç ï¼šä½¿ç”¨æ›¿æ¢ç­–ç•¥å¤„ç†æ— æ•ˆå­—èŠ‚
        byte_data = text.encode('utf-8', errors='replace')
        
        # å®‰å…¨æˆªæ–­ï¼šç¡®ä¿ä¸ç ´åå¤šå­—èŠ‚å­—ç¬¦è¾¹ç•Œ
        safe_length = min(len(byte_data), self.embed_dim)
        truncated = byte_data[:safe_length]
        
        # è½¬æ¢æ•°å€¼å‘é‡
        vec = np.frombuffer(truncated, dtype=np.uint8)
        
        # ç»´åº¦å¤„ç†
        if len(vec) < self.embed_dim:
            # ä½¿ç”¨0ä½œä¸ºå¡«å……æ ‡è®°ï¼ˆåŸè®¾è®¡ä½¿ç”¨-1ä¼šå¯¼è‡´é—®é¢˜ï¼‰
            vec = np.pad(vec, (0, self.embed_dim - len(vec)), 
                         constant_values=0)
        return vec.astype(np.float32)

    def compress_triplet(self, triple: Tuple[str, str, str]) -> np.ndarray:
        """
        ğŸŒ€ğŸŒ€ ä¸‰å…ƒç»„å‹ç¼©æ ¸å¿ƒï¼šä½¿ç”¨å¼ é‡ç½‘ç»œæŠ€æœ¯å‹ç¼©(s,p,o)ä¸‰å…ƒç»„\n
        æŠ€æœ¯è·¯çº¿ï¼š
        1. åˆ†åˆ«ç¼–ç ä¸»è¯­(s)ã€è°“è¯­(p)ã€å®¾è¯­(o)
        2. æ‰§è¡Œå¼ é‡ç½‘ç»œæ”¶ç¼©ï¼šsâŠ—pâ†’çŸ©é˜µ â†’ çŸ©é˜µâŠ—oâ†’ä¸‰é˜¶å¼ é‡
        3. è¾“å‡ºç«‹æ–¹ä½“çŠ¶å‹ç¼©è¡¨ç¤º(DÃ—DÃ—D)\n
        å¯è§†åŒ–ï¼š[s]â†’â¨‚â¨‚â¨‚â”€[p]â†’â—»â—»â”€â¨‚â¨‚â¨‚â”€[o]â†’â—»â—»â—»â—»
        """
        s_vec = self.text_to_tensor(triple[0])
        p_vec = self.text_to_tensor(triple[1])
        o_vec = self.text_to_tensor(triple[2])

        # å¼ é‡æ”¶ç¼©æ¨¡æ‹Ÿç –å¢™å¼ é‡ç½‘ç»œç»“æ„
        tensor = np.tensordot(s_vec, p_vec, axes=0)        # å½¢çŠ¶: (D, D)
        tensor = np.tensordot(tensor, o_vec, axes=0)       # å½¢çŠ¶: (D, D, D)
        return tensor

    def flatten_tensor(self, tensor: np.ndarray) -> np.ndarray:
        """
        ğŸ“¦ğŸ“¦ å¼ é‡å±•å¹³å™¨ï¼šå°†é«˜é˜¶å‹ç¼©å¼ é‡è½¬æ¢ä¸ºä¸€ç»´å‘é‡\n
        ç”¨é€”ï¼š
        - ä¾¿äºå­˜å‚¨åˆ°æ•°æ®åº“
        - é€‚åˆè¾“å…¥MLPç­‰å…¨è¿æ¥ç½‘ç»œ
        - å‡å°‘ä¸‹æ¸¸å¤„ç†å¤æ‚åº¦\n
        æ•°å­¦æ“ä½œï¼šflatten(DÃ—DÃ—D)â†’[DÂ³]
        """
        return tensor.flatten()

    def compress_batch(self, triples: List[Tuple[str, str, str]]) -> List[np.ndarray]:
        """
        ğŸš€ğŸš€ğŸš€ æ‰¹é‡å¤„ç†ç®¡é“ï¼šé«˜æ•ˆå¤„ç†å¤šä¸ªä¸‰å…ƒç»„\n
        ä¼˜åŒ–ç‚¹ï¼š
        - è‡ªåŠ¨å¹¶è¡ŒåŒ–ï¼ˆåˆ©ç”¨numpyå‘é‡åŒ–ï¼‰
        - å†…å­˜é¢„åˆ†é…
        - æµå¼å¤„ç†æ”¯æŒ\n
        è¾“å…¥ï¼š[("s1","p1","o1"), ("s2","p2","o2")...] â†’ è¾“å‡ºï¼š[å¼ é‡1, å¼ é‡2...]
        """
        return [self.compress_triplet(triple) for triple in triples]

def test_triple_compressor():
    """ğŸ§ª å…¨é¢æµ‹è¯•ä¸‰å…ƒç»„å‹ç¼©å™¨åŠŸèƒ½"""
    print("\n=== å¯åŠ¨ Tensor Network å‹ç¼©æ¨¡å—æµ‹è¯• ===")
    
    # 1. åŸºç¡€åŠŸèƒ½æµ‹è¯•
    print("\nğŸ” æµ‹è¯•1: åŸºç¡€åŠŸèƒ½éªŒè¯")
    compressor = TripleCompressor(embed_dim=32)
    
    # æµ‹è¯•æ–‡æœ¬ç¼–ç 
    test_text = "ä½ å¥½ä¸–ç•Œ"
    text_tensor = compressor.text_to_tensor(test_text)
    print(f"æ–‡æœ¬ç¼–ç æµ‹è¯•: è¾“å…¥'{test_text}' â†’ å½¢çŠ¶ {text_tensor.shape} | dtype={text_tensor.dtype}")
    assert text_tensor.shape == (32,), "æ–‡æœ¬ç¼–ç ç»´åº¦é”™è¯¯"
    assert text_tensor.dtype == np.float32, "æ•°æ®ç±»å‹é”™è¯¯"
    
    # æµ‹è¯•ä¸‰å…ƒç»„å‹ç¼©
    triplet = ("çˆ±å› æ–¯å¦", "æå‡º", "ç›¸å¯¹è®º")
    compressed = compressor.compress_triplet(triplet)
    print(f"ä¸‰å…ƒç»„å‹ç¼©: å½¢çŠ¶ {compressed.shape} | ç»´åº¦ä¹˜ç§¯ {np.prod(compressed.shape)}")
    assert compressed.shape == (32, 32, 32), "å‹ç¼©å¼ é‡å½¢çŠ¶é”™è¯¯"
    
    # æµ‹è¯•å±•å¹³åŠŸèƒ½
    flattened = compressor.flatten_tensor(compressed)
    print(f"å¼ é‡å±•å¹³: {flattened.shape[0]}ç»´å‘é‡")
    assert flattened.shape == (32 * 32 * 32,), "å±•å¹³ç»´åº¦é”™è¯¯"
    
    # 2. æ‰¹é‡å¤„ç†æµ‹è¯•
    print("\nğŸ” æµ‹è¯•2: æ‰¹é‡å¤„ç†èƒ½åŠ›")
    batch = [
        ("è‹¹æœ", "æ˜¯", "æ°´æœ"),
        ("ç‰›é¡¿", "å‘ç°", "ä¸‡æœ‰å¼•åŠ›"),
        ("Python", "ç”¨äº", "AIå¼€å‘")
    ]
    batch_results = compressor.compress_batch(batch)
    print(f"æ‰¹é‡å¤„ç†: {len(batch_results)}ä¸ªä¸‰å…ƒç»„ | é¦–ä¸ªå½¢çŠ¶ {batch_results[0].shape}")
    assert len(batch_results) == len(batch), "æ‰¹é‡å¤„ç†æ•°é‡ä¸åŒ¹é…"
    
    # 3. è¾¹ç•Œæ¡ä»¶æµ‹è¯•
    print("\nğŸ” æµ‹è¯•3: è¾¹ç•Œæ¡ä»¶éªŒè¯")
    # çŸ­æ–‡æœ¬æµ‹è¯•
    short_text = "a"
    short_tensor = compressor.text_to_tensor(short_text)
    print(f"çŸ­æ–‡æœ¬æµ‹è¯•({short_text}): é¦–å€¼={short_tensor[0]}, ç¬¬äºŒå€¼={short_tensor[1]}, æœ«å€¼={short_tensor[-1]}")
    assert short_tensor[0] == ord('a'), "é¦–å…ƒç´ ç¼–ç é”™è¯¯"
    assert short_tensor[1] == 0.0, "å¡«å……å€¼é”™è¯¯"
    
    # é•¿æ–‡æœ¬æµ‹è¯•
    long_text = "å¼ é‡ç½‘ç»œå‹ç¼©æŠ€æœ¯" * 10  # è¶…é•¿å­—ç¬¦ä¸²
    long_tensor = compressor.text_to_tensor(long_text)
    print(f"é•¿æ–‡æœ¬æµ‹è¯•: å‰2å­—èŠ‚ [{long_tensor[0]}, {long_tensor[1]}]")
    assert long_tensor.shape == (32,), "é•¿æ–‡æœ¬ç»´åº¦é”™è¯¯"
    
    # ç‰¹æ®Šå­—ç¬¦æµ‹è¯•
    special_char = "â„"
    special_tensor = compressor.text_to_tensor(special_char)
    first_byte = special_char.encode('utf-8')[0]
    print(f"ç‰¹æ®Šå­—ç¬¦æµ‹è¯•: é¦–å€¼ {special_tensor[0]} (åº”ä¸º{first_byte})")
    assert special_tensor[0] == first_byte, "ç‰¹æ®Šå­—ç¬¦ç¼–ç é”™è¯¯"
    
    # ç©ºæ–‡æœ¬æµ‹è¯•
    empty_text = ""
    empty_tensor = compressor.text_to_tensor(empty_text)
    print(f"ç©ºæ–‡æœ¬æµ‹è¯•: æ‰€æœ‰å€¼åº”ä¸º0? {np.all(empty_tensor == 0)}")
    assert np.all(empty_tensor == 0.0), "ç©ºæ–‡æœ¬åº”å…¨å¡«å……ä¸º0"
    
    # 4. å‹ç¼©æ•ˆæœéªŒè¯
    print("\nğŸ” æµ‹è¯•4: å‹ç¼©æ•ˆæœåˆ†æ")
    original_size = 3 * 32  # 3ä¸ª32ç»´å‘é‡
    compressed_size = np.prod(compressed.shape)
    print(f"åŸå§‹å¤§å°: {original_size}å…ƒç´  â†’ å‹ç¼©å: {compressed_size}å…ƒç´ ")
    print(f"å‹ç¼©æ¯”ç‡: {compressed_size/original_size:.1f}x")
    
    # 5. æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
    print("\nğŸ” æµ‹è¯•5: æ•°å€¼ç‰¹æ€§éªŒè¯")
    print(f"å‹ç¼©å¼ é‡èŒƒå›´: [{compressed.min():.2f}, {compressed.max():.2f}]")
    print(f"å‡å€¼: {compressed.mean():.2f} | æ ‡å‡†å·®: {compressed.std():.2f}")
    
    print("\nâœ…âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¨¡å—åŠŸèƒ½æ­£å¸¸ âœ…âœ…")

if __name__ == "__main__":
    test_triple_compressor()