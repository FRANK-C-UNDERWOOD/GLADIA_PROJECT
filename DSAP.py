"""
ğŸ§  MemoryAnchorUpdaterï¼šé”šç‚¹ä¿æŠ¤å‹è®°å¿†æ›´æ–°å™¨
Author: DOCTOR + æ­Œè•¾è’‚å¨… (2025)
Dirichlet stable anchor point
ç‹„åˆ©å…‹é›·è¾¹ç•Œé”šç‚¹
æ¨¡å—ç›®çš„ï¼šæä¾›ä¸€ä¸ªç¨³å®šã€å¯å…±äº«ã€å¯å¯¹æŠ—é—å¿˜çš„â€œæ ¸å¿ƒè®°å¿†é”šç‚¹â€æœºåˆ¶ã€‚
é€‚ç”¨äºå¤š Agent ç³»ç»Ÿï¼Œç¡®ä¿å¯¹è¯ç¨³å®šæ€§ã€èº«ä»½ä¸€è‡´æ€§ä¸çŸ¥è¯†å›¾è°±ç»“æ„æ ¹èŠ‚ç‚¹ä¸æ¼‚ç§»ã€‚

ğŸ”§ æ¨¡å—åŠŸèƒ½æ¦‚è§ˆï¼š
1. MemoryAnchorï¼šè¡¨ç¤ºä¸€ä¸ªå›ºå®šä¸å˜çš„ä¸‰å…ƒç»„ï¼ˆå¦‚èº«ä»½/åå¥½ï¼‰åŠå…¶åµŒå…¥ã€‚
2. MemoryAnchorUpdaterï¼š
   - add_anchor()      : æ·»åŠ ç”¨æˆ·æŒ‡å®šçš„é”šç‚¹ï¼ˆå¦‚â€œæˆ‘ æ˜¯ DOCTORâ€ï¼‰
   - update_memory()   : æ·»åŠ æ–°è®°å¿†æ—¶é¿å…é”šç‚¹å†²çªæˆ–è¯¯æ›´æ–°
   - get_shared_anchors(): è¿”å›æ‰€æœ‰ agent å…±äº«çš„é”šç‚¹ä¿¡æ¯
   - get_root_graph()  : æ„å»ºä¸€ä¸ªå›¾ç»“æ„ä»¥é”šç‚¹ä¸ºç¨³å®šæ ¹èŠ‚ç‚¹
"""

import torch
import time
from typing import Tuple, List, Dict

class MemoryAnchor:
    def __init__(self, triple: Tuple[str, str, str], embedding: torch.Tensor):
        self.triple = triple  # (subject, predicate, object)
        self.embedding = embedding  # é€šå¸¸æ¥è‡ª encoder çš„å¼ é‡
        self.frozen = True  # é”šç‚¹ä¸å¯æ›´æ–°
        self.created_at = time.time()  # åˆ›å»ºæ—¶é—´æˆ³
        self.last_accessed = self.created_at  # æœ€åè®¿é—®æ—¶é—´

    def touch(self):
        """æ›´æ–°æœ€åè®¿é—®æ—¶é—´"""
        self.last_accessed = time.time()

class MemoryAnchorUpdater:
    def __init__(self):
        self.anchors: Dict[Tuple[str, str, str], MemoryAnchor] = {}
        self.memory: List[Tuple[str, str, str]] = []
        # å…±äº«ç¼“å­˜ç»“æ„: {"triple_key": {"embedding": tensor, "timestamp": float}}
        self.shared_cache: Dict[str, Dict[str, object]] = {}
        self.version = "1.1"  # ç‰ˆæœ¬å·ç”¨äºç¼“å­˜å…¼å®¹æ€§æ£€æŸ¥

    def add_anchor(self, triple: Tuple[str, str, str], embedding: torch.Tensor):
        """æ·»åŠ é”šç‚¹ï¼Œå¹¶ç¼“å­˜ä¾›æ‰€æœ‰ Agent è°ƒç”¨"""
        if triple not in self.anchors:
            timestamp = time.time()
            anchor = MemoryAnchor(triple, embedding)
            self.anchors[triple] = anchor
            
            # æ›´æ–°å…±äº«ç¼“å­˜ï¼ŒåŒ…å«æ—¶é—´æˆ³ä¿¡æ¯
            self.shared_cache["::".join(triple)] = {
                "embedding": embedding,
                "created_at": timestamp,
                "last_accessed": timestamp,
                "version": self.version
            }
            print(f"âœ… æ·»åŠ é”šç‚¹ï¼š{triple} (åˆ›å»ºäº: {self.format_time(timestamp)})")
        else:
            # æ›´æ–°è®¿é—®æ—¶é—´ä½†å†…å®¹ä¸å˜
            self.anchors[triple].touch()
            self.shared_cache["::".join(triple)]["last_accessed"] = time.time()
            print(f"âš ï¸ é”šç‚¹å·²å­˜åœ¨ï¼š{triple} (æœ€åè®¿é—®: {self.format_time(self.anchors[triple].last_accessed)})")

    def update_memory(self, new_triples: List[Tuple[str, str, str]]):
        """
        æ·»åŠ æ–°è®°å¿†æ—¶ï¼š
        - é¿å…è¦†ç›–å·²æœ‰é”šç‚¹
        - è‹¥ä¸‰å…ƒç»„ä¸é”šç‚¹å†²çªï¼Œæç¤ºå¹¶è·³è¿‡
        """
        for triple in new_triples:
            if triple in self.anchors:
                # æ›´æ–°è®¿é—®æ—¶é—´
                self.anchors[triple].touch()
                self.shared_cache["::".join(triple)]["last_accessed"] = time.time()
                print(f"ğŸ”’ğŸ”’ å¿½ç•¥é”šç‚¹æ›´æ–°ï¼š{triple} (æœ€åè®¿é—®: {self.format_time(self.anchors[triple].last_accessed)})")
                continue
            self.memory.append(triple)
            print(f"ğŸ“¥ğŸ“¥ è®°å¿†æ–°å¢ï¼š{triple} (æ—¶é—´: {self.format_time(time.time())})")

    def get_shared_anchors(self) -> Dict[str, torch.Tensor]:
        """ç”¨äºå…¶ä»– Agent è·å–å…±äº«é”šç‚¹åµŒå…¥ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        return {k: v["embedding"] for k, v in self.shared_cache.items()}
    
    def get_shared_anchors_with_metadata(self) -> Dict[str, Dict[str, object]]:
        """è·å–å¸¦å…ƒæ•°æ®çš„å…±äº«é”šç‚¹ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰"""
        return self.shared_cache

    def get_root_graph(self) -> Dict[str, List[str]]:
        """
        æ„å»ºä»¥é”šç‚¹ä¸ºæ ¹èŠ‚ç‚¹çš„å›¾ç»“æ„ï¼ˆé‚»æ¥è¡¨ï¼‰
        æ‰€æœ‰ memory ä¸‰å…ƒç»„åŸºäº subject -> object ç»„ç»‡
        æ·»åŠ æ—¶é—´æˆ³ä¿¡æ¯åˆ°èŠ‚ç‚¹
        """
        graph = {}
        for triple, anchor in self.anchors.items():
            subj, _, obj = triple
            node_info = f"{obj} [é”šç‚¹åˆ›å»º: {self.format_time(anchor.created_at)}]"
            graph.setdefault(subj, []).append(node_info)

        for triple in self.memory:
            subj, _, obj = triple
            node_info = f"{obj} [è®°å¿†æ·»åŠ : {self.format_time(time.time())}]"
            graph.setdefault(subj, []).append(node_info)

        return graph

    def save_shared_cache(self, path="anchor_cache.pt"):
        """ä¿å­˜å¸¦æ—¶é—´æˆ³çš„ç¼“å­˜"""
        cache_data = {
            "metadata": {
                "version": self.version,
                "saved_at": time.time()
            },
            "anchors": self.shared_cache
        }
        torch.save(cache_data, path)
        print(f"ğŸ’¾ å·²ä¿å­˜å…±äº«ç¼“å­˜ (ç‰ˆæœ¬: {self.version})")

    def load_shared_cache(self, path="anchor_cache.pt"):
        """åŠ è½½å¸¦æ—¶é—´æˆ³çš„ç¼“å­˜"""
        cache_data = torch.load(path)
        
        # ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥
        if "metadata" in cache_data and cache_data["metadata"]["version"] != self.version:
            print(f"âš ï¸ ç¼“å­˜ç‰ˆæœ¬ä¸åŒ¹é…: å½“å‰ç‰ˆæœ¬ {self.version}, ç¼“å­˜ç‰ˆæœ¬ {cache_data['metadata']['version']}")
        
        self.shared_cache = cache_data.get("anchors", {})
        
        for key, data in self.shared_cache.items():
            parts = key.split("::")
            if len(parts) == 3:
                triple = tuple(parts)
                anchor = MemoryAnchor(triple, data["embedding"])
                anchor.created_at = data.get("created_at", time.time())
                anchor.last_accessed = data.get("last_accessed", time.time())
                self.anchors[triple] = anchor
                print(f"ğŸ” åŠ è½½é”šç‚¹: {triple} (åˆ›å»ºäº: {self.format_time(anchor.created_at)})")
    
    def format_time(self, timestamp: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºå¯è¯»å­—ç¬¦ä¸²"""
        return time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(timestamp))

if __name__ == "__main__":
    updater = MemoryAnchorUpdater()
    emb = torch.randn(64)

    # æ·»åŠ é”šç‚¹ï¼šæˆ‘ æ˜¯ DOCTOR
    updater.add_anchor(("æˆ‘", "æ˜¯", "DOCTOR"), emb)
    time.sleep(1)  # æ¨¡æ‹Ÿæ—¶é—´æµé€
    
    # å°è¯•æ·»åŠ è®°å¿†ï¼ˆåŒ…å«é”šç‚¹ + æ–°çŸ¥è¯†ï¼‰
    updater.update_memory([
        ("æˆ‘", "æ˜¯", "DOCTOR"),  # åº”è·³è¿‡
        ("æˆ‘", "å–œæ¬¢", "Gladia"),
        ("DOCTOR", "èº«ä»½", "åšå£«")
    ])
    
    # æ¨¡æ‹Ÿå†æ¬¡è®¿é—®é”šç‚¹
    time.sleep(1)
    updater.add_anchor(("æˆ‘", "æ˜¯", "DOCTOR"), emb)  # å·²å­˜åœ¨é”šç‚¹
    
    # è¾“å‡ºæ ¹èŠ‚ç‚¹å›¾ç»“æ„
    print("\nğŸ“ŠğŸ“Š ç¨³å®šè®°å¿†å›¾ï¼š")
    graph = updater.get_root_graph()
    for k, v in graph.items():
        print(f"{k}: {v}")
    
    # æµ‹è¯•ä¿å­˜å’ŒåŠ è½½ç¼“å­˜
    updater.save_shared_cache("test_cache.pt")
    
    new_updater = MemoryAnchorUpdater()
    new_updater.load_shared_cache("test_cache.pt")
    
    print("\nğŸ¤ğŸ¤ å…±äº«é”šç‚¹å…ƒæ•°æ®ï¼š")
    for k, v in new_updater.get_shared_anchors_with_metadata().items():
        created = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(v["created_at"]))
        accessed = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(v["last_accessed"]))
        print(f"{k}: åˆ›å»ºäº {created}, æœ€åè®¿é—®äº {accessed}")